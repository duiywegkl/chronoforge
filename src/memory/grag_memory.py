from collections import deque
from typing import List, Dict, Any, Optional
from loguru import logger

from src.memory.basic_memory import BasicMemory
from src.graph.knowledge_graph import KnowledgeGraph

class GRAGMemory:
    """
    GRAGä¸‰å±‚è®°å¿†ç³»ç»Ÿï¼Œæ•´åˆäº†çƒ­ã€æ¸©ã€å†·ä¸‰ç§è®°å¿†ã€‚
    - çƒ­è®°å¿† (Hot Memory): æœ€è¿‘çš„å¯¹è¯å†å²ï¼Œä½¿ç”¨ BasicMemory çš„ dequeã€‚
    - æ¸©è®°å¿† (Warm Memory): å…³é”®çŠ¶æ€é”®å€¼å¯¹ï¼Œä½¿ç”¨ BasicMemory çš„ state_tableã€‚
    - å†·è®°å¿† (Cold Memory): ç»“æ„åŒ–çš„çŸ¥è¯†å›¾è°±ï¼Œä½¿ç”¨ KnowledgeGraphã€‚
    """

    def __init__(self, hot_memory_size: int = 10, graph_save_path: Optional[str] = None):
        """
        åˆå§‹åŒ–ä¸‰å±‚è®°å¿†ç³»ç»Ÿã€‚

        Args:
            hot_memory_size (int): çƒ­è®°å¿†è¦ä¿ç•™çš„æœ€è¿‘å¯¹è¯è½®æ•°ã€‚
            graph_save_path (Optional[str]): çŸ¥è¯†å›¾è°±çš„ä¿å­˜/åŠ è½½è·¯å¾„ã€‚
        """
        # çƒ­ã€æ¸©è®°å¿†å±‚ (ç»§æ‰¿è‡ªBasicMemoryçš„åŠŸèƒ½)
        self.basic_memory = BasicMemory(max_size=hot_memory_size)
        
        # å†·è®°å¿†å±‚
        self.knowledge_graph = KnowledgeGraph()
        self.graph_save_path = graph_save_path
        if self.graph_save_path:
            self.knowledge_graph.load_graph(self.graph_save_path)

        # åŠ è½½UIä¸­çš„å®ä½“æ•°æ®åˆ°çŸ¥è¯†å›¾è°±
        self._load_entities_from_json()

        # æ•°æ®å˜åŒ–è¿½è¸ª
        self._data_changed = False
        self._last_conversation_count = 0

        logger.info("GRAGMemory initialized with Hot, Warm, and Cold memory layers.")

    def _load_entities_from_json(self):
        """ä»UIçš„entities.jsonæ–‡ä»¶åŠ è½½å®ä½“åˆ°çŸ¥è¯†å›¾è°±ä¸­"""
        import json
        import os
        from pathlib import Path
        
        # å®ä½“æ–‡ä»¶è·¯å¾„
        entities_file = Path(__file__).parent.parent.parent / "data" / "entities.json"
        
        if not entities_file.exists():
            logger.info(f"å®ä½“æ–‡ä»¶ {entities_file} ä¸å­˜åœ¨ï¼Œè·³è¿‡åŠ è½½")
            return
        
        try:
            with open(entities_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            entities = data.get('entities', [])
            if not entities:
                logger.info("å®ä½“æ–‡ä»¶ä¸­æ²¡æœ‰å®ä½“æ•°æ®")
                return
            
            entities_loaded = 0
            for entity in entities:
                entity_name = entity.get('name')
                entity_type = entity.get('type', 'concept')
                
                if not entity_name:
                    logger.warning(f"è·³è¿‡æ²¡æœ‰åç§°çš„å®ä½“: {entity}")
                    continue
                
                # å‡†å¤‡å±æ€§
                attributes = {}
                if entity.get('description'):
                    attributes['description'] = entity['description']
                if entity.get('created_time'):
                    attributes['created_time'] = entity['created_time']
                if entity.get('last_modified'):
                    attributes['last_modified'] = entity['last_modified']
                
                # æ·»åŠ åŠ¨æ€å±æ€§
                if entity.get('attributes'):
                    for key, value in entity['attributes'].items():
                        attributes[key] = value
                
                # å°†å®ä½“æ·»åŠ åˆ°çŸ¥è¯†å›¾è°±
                self.knowledge_graph.add_or_update_node(entity_name, entity_type, **attributes)
                entities_loaded += 1
            
            logger.info(f"âœ… æˆåŠŸä» entities.json åŠ è½½äº† {entities_loaded} ä¸ªå®ä½“åˆ°çŸ¥è¯†å›¾è°±")
            
            # åŠ è½½å…³ç³»
            relationships = data.get('relationships', [])
            relationships_loaded = 0
            
            for rel in relationships:
                try:
                    source = rel.get('source')
                    target = rel.get('target')
                    relationship_type = rel.get('relationship', 'related_to')
                    description = rel.get('description', '')
                    
                    if source and target:
                        # æ£€æŸ¥æºèŠ‚ç‚¹å’Œç›®æ ‡èŠ‚ç‚¹æ˜¯å¦å­˜åœ¨
                        if (self.knowledge_graph.graph.has_node(source) and 
                            self.knowledge_graph.graph.has_node(target)):
                            
                            # æ·»åŠ å…³ç³»å±æ€§
                            rel_attrs = {'relationship': relationship_type}
                            if description:
                                rel_attrs['description'] = description
                            
                            # æ·»åŠ å…¶ä»–å±æ€§
                            if rel.get('attributes'):
                                rel_attrs.update(rel['attributes'])
                            
                            # æ·»åŠ è¾¹åˆ°çŸ¥è¯†å›¾è°±
                            self.knowledge_graph.graph.add_edge(source, target, **rel_attrs)
                            relationships_loaded += 1
                            
                        else:
                            logger.warning(f"è·³è¿‡å…³ç³» {source} -> {target}ï¼šèŠ‚ç‚¹ä¸å­˜åœ¨")
                    else:
                        logger.warning(f"è·³è¿‡æ— æ•ˆå…³ç³»: {rel}")
                        
                except Exception as e:
                    logger.warning(f"åŠ è½½å…³ç³»å¤±è´¥ {rel}: {e}")
            
            logger.info(f"âœ… æˆåŠŸä» entities.json åŠ è½½äº† {relationships_loaded} ä¸ªå…³ç³»åˆ°çŸ¥è¯†å›¾è°±")
            
        except Exception as e:
            logger.error(f"âŒ ä» entities.json åŠ è½½å®ä½“å¤±è´¥: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    
    def sync_entities_to_json(self):
        """å°†çŸ¥è¯†å›¾è°±ä¸­çš„å®ä½“åŒæ­¥åˆ°entities.jsonæ–‡ä»¶"""
        import json
        import time
        from pathlib import Path
        
        # å®ä½“æ–‡ä»¶è·¯å¾„
        entities_file = Path(__file__).parent.parent.parent / "data" / "entities.json"
        entities_file.parent.mkdir(exist_ok=True, parents=True)
        
        try:
            entities = []
            
            # ä»çŸ¥è¯†å›¾è°±ä¸­è·å–æ‰€æœ‰èŠ‚ç‚¹
            for node_id, attrs in self.knowledge_graph.graph.nodes(data=True):
                entity = {
                    'name': node_id,
                    'type': attrs.get('type', 'concept'),
                    'description': attrs.get('description', ''),
                    'created_time': attrs.get('created_time', time.time()),
                    'last_modified': attrs.get('last_modified', time.time()),
                    'attributes': {}
                }
                
                # æ·»åŠ åŠ¨æ€å±æ€§ï¼Œæ’é™¤ç³»ç»Ÿå±æ€§
                excluded_keys = {'type', 'description', 'created_time', 'last_modified'}
                for key, value in attrs.items():
                    if key not in excluded_keys:
                        entity['attributes'][key] = value
                
                entities.append(entity)
            
            # è·å–æ‰€æœ‰å…³ç³»
            relationships = []
            for source, target, attrs in self.knowledge_graph.graph.edges(data=True):
                relationship = {
                    'source': source,
                    'target': target,
                    'relationship': attrs.get('relationship', 'related_to'),
                    'description': attrs.get('description', ''),
                    'attributes': {k: v for k, v in attrs.items() if k not in ['relationship', 'description']}
                }
                relationships.append(relationship)
            
            # ä¿å­˜åˆ°æ–‡ä»¶
            data = {
                'entities': entities,
                'relationships': relationships,  # æ–°å¢ï¼šä¿å­˜å…³ç³»
                'last_modified': time.time()
            }
            
            with open(entities_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… æˆåŠŸåŒæ­¥ {len(entities)} ä¸ªå®ä½“å’Œ {len(relationships)} ä¸ªå…³ç³»åˆ° entities.json")
            
        except Exception as e:
            logger.error(f"âŒ åŒæ­¥å®ä½“åˆ° entities.json å¤±è´¥: {e}")
            logger.exception("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")

    def reload_entities_from_json(self):
        """é‡æ–°åŠ è½½entities.jsonæ–‡ä»¶ä¸­çš„å®ä½“"""
        logger.info("ğŸ”„ é‡æ–°åŠ è½½å®ä½“æ•°æ®...")
        
        # æ¸…ç©ºç°æœ‰èŠ‚ç‚¹ï¼ˆåªæ¸…ç©ºå®ä½“èŠ‚ç‚¹ï¼Œä¿ç•™å…¶ä»–èŠ‚ç‚¹ï¼‰
        nodes_to_remove = []
        for node_id, attrs in self.knowledge_graph.graph.nodes(data=True):
            if attrs.get('type') in ['character', 'location', 'item', 'event', 'concept']:
                nodes_to_remove.append(node_id)
        
        for node_id in nodes_to_remove:
            self.knowledge_graph.graph.remove_node(node_id)
        
        # é‡æ–°åŠ è½½
        self._load_entities_from_json()
        
        logger.info("âœ… å®ä½“æ•°æ®é‡æ–°åŠ è½½å®Œæˆ")

    # --- Interface for Hot and Warm Memory ---

    def add_conversation(self, user_input: str, ai_response: str):
        """å‘çƒ­è®°å¿†ä¸­æ·»åŠ ä¸€è½®å¯¹è¯ã€‚"""
        self.basic_memory.add_conversation(user_input, ai_response)
        self._data_changed = True  # æ ‡è®°æ•°æ®å·²å˜åŒ–

    def get_recent_conversation(self, turns: int = 5) -> str:
        """è·å–æœ€è¿‘å‡ è½®çš„å¯¹è¯å†å²ã€‚"""
        return self.basic_memory.get_context(recent_turns=turns)

    def update_state(self, key: str, value: Any):
        """æ›´æ–°æ¸©è®°å¿†ä¸­çš„çŠ¶æ€ã€‚"""
        self.basic_memory.update_state(key, value)
        self._data_changed = True  # æ ‡è®°æ•°æ®å·²å˜åŒ–

    def get_state(self, key: str) -> Any:
        """ä»æ¸©è®°å¿†ä¸­è·å–çŠ¶æ€ã€‚"""
        return self.basic_memory.get_state(key)

    # --- Interface for Cold Memory (Knowledge Graph) ---

    def add_or_update_node(self, node_id: str, node_type: str, **kwargs):
        """åœ¨çŸ¥è¯†å›¾è°±ä¸­æ·»åŠ æˆ–æ›´æ–°èŠ‚ç‚¹ï¼Œå¸¦æœ‰å†²çªè§£å†³æœºåˆ¶ã€‚"""
        self.knowledge_graph.add_or_update_node_with_conflict_resolution(node_id, node_type, **kwargs)
        self._data_changed = True  # æ ‡è®°æ•°æ®å·²å˜åŒ–

    def add_edge(self, source: str, target: str, relationship: str, **kwargs):
        """åœ¨çŸ¥è¯†å›¾è°±ä¸­æ·»åŠ å…³ç³»ã€‚"""
        self.knowledge_graph.add_edge(source, target, relationship, **kwargs)
        self._data_changed = True  # æ ‡è®°æ•°æ®å·²å˜åŒ–

    def delete_node(self, node_id: str) -> bool:
        """ä»çŸ¥è¯†å›¾è°±ä¸­åˆ é™¤èŠ‚ç‚¹åŠå…¶æ‰€æœ‰å…³ç³»ã€‚"""
        result = self.knowledge_graph.delete_node(node_id)
        if result:
            self._data_changed = True  # æ ‡è®°æ•°æ®å·²å˜åŒ–
        return result

    def delete_edge(self, source: str, target: str, relationship: str = None) -> bool:
        """ä»çŸ¥è¯†å›¾è°±ä¸­åˆ é™¤è¾¹ã€‚"""
        result = self.knowledge_graph.delete_edge(source, target, relationship)
        if result:
            self._data_changed = True  # æ ‡è®°æ•°æ®å·²å˜åŒ–
        return result

    def mark_node_as_deleted(self, node_id: str, reason: str = ""):
        """è½¯åˆ é™¤èŠ‚ç‚¹ï¼Œæ ‡è®°ä¸ºå·²åˆ é™¤ä½†ä¿ç•™å†å²è®°å½•ã€‚"""
        self.knowledge_graph.mark_node_as_deleted(node_id, reason)

    def get_active_nodes(self) -> List[str]:
        """è·å–æ‰€æœ‰æ´»è·ƒï¼ˆæœªåˆ é™¤ï¼‰çš„èŠ‚ç‚¹ã€‚"""
        return self.knowledge_graph.get_active_nodes()

    def cleanup_old_deleted_nodes(self, days_threshold: int = 30) -> int:
        """æ¸…ç†è¶…è¿‡æŒ‡å®šå¤©æ•°çš„å·²åˆ é™¤èŠ‚ç‚¹ã€‚"""
        return self.knowledge_graph.cleanup_deleted_nodes(days_threshold)

    def get_knowledge_graph_context(self, entity_ids: List[str], depth: int = 1) -> str:
        """
        ä»çŸ¥è¯†å›¾è°±ä¸­ä¸ºæŒ‡å®šå®ä½“æå–ä¸Šä¸‹æ–‡ã€‚

        Args:
            entity_ids (List[str]): éœ€è¦æ£€ç´¢çš„æ ¸å¿ƒå®ä½“IDã€‚
            depth (int): æ£€ç´¢æ·±åº¦ã€‚

        Returns:
            str: çŸ¥è¯†å›¾è°±å­å›¾çš„æ–‡æœ¬è¡¨ç¤ºã€‚
        """
        if not entity_ids:
            return "No entities provided for knowledge graph retrieval."
        
        subgraph = self.knowledge_graph.get_subgraph_for_context(entity_ids, depth)
        return self.knowledge_graph.to_text_representation(subgraph)

    # --- Unified Retrieval ---

    def retrieve_context_for_prompt(self, entities_in_query: List[str], recent_turns: int = 3) -> str:
        """
        ä¸ºLLMçš„æç¤ºè¯æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡ã€‚
        æ•´åˆäº†æ‰€æœ‰è®°å¿†å±‚çš„ä¿¡æ¯ã€‚

        Args:
            entities_in_query (List[str]): ä»å½“å‰ç”¨æˆ·è¾“å…¥ä¸­è¯†åˆ«å‡ºçš„æ ¸å¿ƒå®ä½“ã€‚
            recent_turns (int): è¦åŒ…å«çš„æœ€è¿‘å¯¹è¯è½®æ•°ã€‚

        Returns:
            str: æ ¼å¼åŒ–åçš„ã€å¯ç›´æ¥ç”¨äºPromptçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ã€‚
        """
        # 1. ä»çƒ­è®°å¿†è·å–æœ€è¿‘å¯¹è¯
        conversation_context = self.get_recent_conversation(turns=recent_turns)
        
        # 2. ä»æ¸©è®°å¿†è·å–å…³é”®çŠ¶æ€ (è¿™é‡Œå¯ä»¥æ ¹æ®å®ä½“æ¥å†³å®šæŸ¥è¯¢å“ªäº›çŠ¶æ€)
        # ç®€å•èµ·è§ï¼Œæˆ‘ä»¬å…ˆå‡è®¾æœ‰ä¸€ä¸ªå…¨å±€çŠ¶æ€éœ€è¦å±•ç¤º
        world_time = self.get_state("world_time")
        world_state_context = f"[Current World State]\n- World Time: {world_time if world_time else 'Not set'}\n"

        # 3. ä»å†·è®°å¿†è·å–ç›¸å…³çš„çŸ¥è¯†å›¾è°±ä¿¡æ¯
        graph_context = self.get_knowledge_graph_context(entities_in_query, depth=1)

        # 4. ç»„åˆæ‰€æœ‰ä¸Šä¸‹æ–‡
        full_context = (
            f"## Recent Conversation History\n{conversation_context}\n\n"
            f"## {world_state_context}\n"
            f"## Relevant Knowledge Graph\n{graph_context}"
        )

        logger.info("Generated combined context for prompt.")
        return full_context

    def save_all_memory(self):
        """åªåœ¨æœ‰æ•°æ®å˜åŒ–æ—¶ä¿å­˜è®°å¿†çŠ¶æ€ã€‚"""
        if not self._data_changed:
            logger.info("æ²¡æœ‰æ•°æ®å˜åŒ–ï¼Œè·³è¿‡ä¿å­˜")
            return
        
        # ä¿å­˜çƒ­ã€æ¸©è®°å¿†
        self.basic_memory.save_to_file()
        
        # ä¿å­˜å†·è®°å¿† (çŸ¥è¯†å›¾è°±)
        if self.graph_save_path:
            self.knowledge_graph.save_graph(self.graph_save_path)
        else:
            logger.warning("Knowledge graph save path is not set. Graph will not be saved.")
        
        # é‡ç½®å˜åŒ–æ ‡è®°
        self._data_changed = False
        logger.info("è®°å¿†çŠ¶æ€å·²ä¿å­˜")
    
    def clear_all(self):
        """æ¸…ç©ºæ‰€æœ‰è®°å¿†å±‚çš„æ•°æ®"""
        try:
            # æ¸…ç©ºçƒ­ã€æ¸©è®°å¿†
            self.basic_memory.conversation_history.clear()
            self.basic_memory.state_table.clear()
            
            # æ¸…ç©ºå†·è®°å¿†ï¼ˆçŸ¥è¯†å›¾è°±ï¼‰
            self.knowledge_graph.clear()
            
            # åŒæ­¥æ¸…ç©ºentities.jsonæ–‡ä»¶
            self.sync_entities_to_json()
            
            # é‡ç½®å˜åŒ–æ ‡è®°
            self._data_changed = True
            self._last_conversation_count = 0
            
            logger.info("æ‰€æœ‰è®°å¿†å±‚æ•°æ®å·²æ¸…ç©ºï¼ŒåŒ…æ‹¬entities.jsonæ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"æ¸…ç©ºè®°å¿†æ•°æ®å¤±è´¥: {e}")
            raise
